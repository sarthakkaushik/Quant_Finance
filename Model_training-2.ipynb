{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance pandas numpy scikit-learn xgboost lightgbm tensorflow matplotlib optuna ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ta\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, GRU\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "       \n",
    "    stock = yf.Ticker(symbol)\n",
    "    df = stock.history(start=start_date, end=end_date)\n",
    "    # return df.reset_index()\n",
    "    return df\n",
    "    \n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    df['SMA_20'] = ta.trend.sma_indicator(df['Close'], window=20)\n",
    "    df['SMA_50'] = ta.trend.sma_indicator(df['Close'], window=50)\n",
    "    df['EMA_20'] = ta.trend.ema_indicator(df['Close'], window=20)\n",
    "    df['MACD'] = ta.trend.macd_diff(df['Close'])\n",
    "    df['ADX'] = ta.trend.adx(df['High'], df['Low'], df['Close'])\n",
    "    df['RSI'] = ta.momentum.rsi(df['Close'])\n",
    "    df['Stoch_Osc'] = ta.momentum.stoch(df['High'], df['Low'], df['Close'])\n",
    "    df['Williams_R'] = ta.momentum.williams_r(df['High'], df['Low'], df['Close'])\n",
    "    df['BBlow'], df['BBmid'], df['BBupp'] = ta.volatility.bollinger_hband_indicator(df['Close']), ta.volatility.bollinger_mavg(df['Close']), ta.volatility.bollinger_lband_indicator(df['Close'])\n",
    "    df['ATR'] = ta.volatility.average_true_range(df['High'], df['Low'], df['Close'])\n",
    "    df['OBV'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])\n",
    "    df['CMF'] = ta.volume.chaikin_money_flow(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "\n",
    "    df['Keltner_Channel_Upper'], df['Keltner_Channel_Lower'] = ta.volatility.keltner_channel_hband(df['High'], df['Low'], df['Close']), ta.volatility.keltner_channel_lband(df['High'], df['Low'], df['Close'])\n",
    "    df['Mass_Index'] = ta.trend.mass_index(df['High'], df['Low'])\n",
    "    df['TRIX'] = ta.trend.trix(df['Close'])\n",
    "    df['Ultimate_Oscillator'] = ta.momentum.ultimate_oscillator(df['High'], df['Low'], df['Close'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_derived_features(df):\n",
    "    df['Price_Change'] = df['Close'].diff()\n",
    "    df['Pct_Change'] = df['Close'].pct_change()\n",
    "    df['VWAP'] = (df['Volume'] * (df['High'] + df['Low'] + df['Close']) / 3).cumsum() / df['Volume'].cumsum()\n",
    "    df['High_Volume'] = (df['Volume'] > df['Volume'].rolling(window=20).mean() * 1.5).astype(int)\n",
    "    df['Significant_Price_Move'] = ((df['Close'] - df['Open']).abs() > df['Close'].rolling(window=20).std()).astype(int)\n",
    "    df['Volume_Spike_With_Price_Move'] = ((df['Volume'] > df['Volume'].rolling(window=20).mean() * 2) & (df['Significant_Price_Move'] == 1)).astype(int)\n",
    "    df['Relative_Volume'] = df['Volume'] / df['Volume'].rolling(window=20).mean()\n",
    "    df['Day_of_Week'] = df.index.dayofweek\n",
    "    df['Is_Month_End'] = df.index.is_month_end.astype(int)\n",
    "    df['Price_Momentum'] = df['Close'] - df['Close'].shift(10)\n",
    "    df['Volume_Price_Trend'] = (df['Volume'] * (df['Close'] - df['Close'].shift(1))).cumsum()\n",
    "    df['Acceleration'] = df['Price_Change'] - df['Price_Change'].shift(1)\n",
    "\n",
    "    # Add polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[['Close', 'Volume']])\n",
    "    df['Close_Squared'] = poly_features[:, 2]\n",
    "    df['Volume_Squared'] = poly_features[:, 3]\n",
    "    df['Close_Volume_Interaction'] = poly_features[:, 4]\n",
    "\n",
    "# Add lagged features\n",
    "    for i in [1, 2, 3, 5, 10]:\n",
    "        df[f'Close_Lag_{i}'] = df['Close'].shift(i)\n",
    "        df[f'Volume_Lag_{i}'] = df['Volume'].shift(i)\n",
    "\n",
    "# Add rolling window features\n",
    "    for window in [5, 10, 20]:\n",
    "        df[f'Close_Roll_Mean_{window}'] = df['Close'].rolling(window=window).mean()\n",
    "        df[f'Close_Roll_Std_{window}'] = df['Close'].rolling(window=window).std()\n",
    "        df[f'Volume_Roll_Mean_{window}'] = df['Volume'].rolling(window=window).mean()\n",
    "\n",
    "    # Add Fourier features\n",
    "    for period in [5, 10, 21]:\n",
    "        df[f'Fourier_Cos_{period}'] = np.cos(2 * np.pi * df.index.dayofyear / period)\n",
    "        df[f'Fourier_Sin_{period}'] = np.sin(2 * np.pi * df.index.dayofyear / period)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_data_for_model(df):\n",
    "    df = df.sort_index()\n",
    "    df['Target'] = df['Close'].shift(-1)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    features = [col for col in df.columns if col not in ['Target', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    X = df[features]\n",
    "    y = df['Target']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def feature_selection(X, y, k=50):\n",
    "    selector = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    return X[selected_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X, n_components=0.95):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca, pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_and_scale_data(X, y, test_size=0.2):\n",
    "    \n",
    "#     # Ensure data is sorted by date\n",
    "#     # X = X.sort_index()\n",
    "#     # y = y.sort_index()\n",
    "#     # Use TimeSeriesSplit for more appropriate validation\n",
    "#     tscv = TimeSeriesSplit(n_splits=5)\n",
    "#     for train_index, test_index in tscv.split(X):\n",
    "#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # Use RobustScaler to handle outliers better\n",
    "#     scaler = RobustScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "#     return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "def split_and_scale_data(X, y, test_size=0.2):\n",
    "    # Ensure X and y are pandas DataFrames/Series\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    # Ensure data is sorted by date\n",
    "    X = X.sort_index()\n",
    "    y = y.sort_index()\n",
    "    \n",
    "    # Use TimeSeriesSplit for more appropriate validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # We'll use the last split for our final train/test set\n",
    "    train_index, test_index = list(tscv.split(X))[-1]\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Use RobustScaler to handle outliers better\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(64, return_sequences=True, input_shape=input_shape)),\n",
    "        Dropout(0.2),\n",
    "        Bidirectional(LSTM(32)),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber')  # Huber loss for robustness\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(64, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        GRU(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    xgb_params = {\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-3, 1.0),\n",
    "        'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 300),\n",
    "        'min_child_weight': trial.suggest_int('xgb_min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_uniform('xgb_subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('xgb_colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "    \n",
    "    lgb_params = {\n",
    "        'num_leaves': trial.suggest_int('lgb_num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_loguniform('lgb_learning_rate', 1e-3, 1.0),\n",
    "        'n_estimators': trial.suggest_int('lgb_n_estimators', 50, 300),\n",
    "        'min_child_samples': trial.suggest_int('lgb_min_child_samples', 1, 100),\n",
    "        'subsample': trial.suggest_uniform('lgb_subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('lgb_colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "    # Added hyperparameters for GRU\n",
    "    gru_units = trial.suggest_int('gru_units', 32, 128)\n",
    "    gru_layers = trial.suggest_int('gru_layers', 1, 3)\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    lstm_model = create_lstm_model((X_train_scaled.shape[1], 1))\n",
    "    gru_model = create_gru_model((X_train_scaled.shape[1], 1))\n",
    "    rf_model = RandomForestRegressor(n_estimators=100)\n",
    "    \n",
    "    stacked_model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('xgb', xgb_model),\n",
    "            ('lgb', lgb_model),\n",
    "            ('lstm', lstm_model),\n",
    "            ('gru', gru_model),\n",
    "            ('rf', rf_model)\n",
    "        ],\n",
    "        final_estimator=xgb.XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=100)\n",
    "    )\n",
    "    \n",
    "    stacked_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = stacked_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100)  # Increased number of trials\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    \n",
    "    # [Create models with best parameters]\n",
    "    \n",
    "    stacked_model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('xgb', xgb_model),\n",
    "            ('lgb', lgb_model),\n",
    "            ('lstm', lstm_model),\n",
    "            ('gru', gru_model),\n",
    "            ('rf', rf_model)\n",
    "        ],\n",
    "        final_estimator=xgb.XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=100)\n",
    "    )\n",
    "    \n",
    "    # Use early stopping and learning rate reduction\n",
    "    early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    lr_reducer = ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    \n",
    "    stacked_model.fit(X_train, y_train, \n",
    "                      lstm__callbacks=[early_stopping, lr_reducer],\n",
    "                      gru__callbacks=[early_stopping, lr_reducer])\n",
    "    return stacked_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"R-squared Score: {r2}\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(y_test, y_pred):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test.index, y_test.values, label='Actual')\n",
    "    plt.plot(y_test.index, y_pred, label='Predicted')\n",
    "    plt.title('Actual vs Predicted Stock Prices')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day(model, scaler, last_data_point):\n",
    "    last_data_point_scaled = scaler.transform(last_data_point.values.reshape(1, -1))\n",
    "    next_day_prediction = model.predict(last_data_point_scaled)[0]\n",
    "    return next_day_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-19 00:00:00+05:30</th>\n",
       "      <td>1325.683498</td>\n",
       "      <td>1329.959932</td>\n",
       "      <td>1276.777905</td>\n",
       "      <td>1281.918579</td>\n",
       "      <td>21157927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-20 00:00:00+05:30</th>\n",
       "      <td>1282.919525</td>\n",
       "      <td>1316.448343</td>\n",
       "      <td>1267.451656</td>\n",
       "      <td>1304.483521</td>\n",
       "      <td>27660492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21 00:00:00+05:30</th>\n",
       "      <td>1305.666277</td>\n",
       "      <td>1329.732380</td>\n",
       "      <td>1296.567574</td>\n",
       "      <td>1311.353027</td>\n",
       "      <td>19583990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22 00:00:00+05:30</th>\n",
       "      <td>1320.952305</td>\n",
       "      <td>1326.593448</td>\n",
       "      <td>1297.932505</td>\n",
       "      <td>1302.527344</td>\n",
       "      <td>18914486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-26 00:00:00+05:30</th>\n",
       "      <td>1317.631133</td>\n",
       "      <td>1319.041449</td>\n",
       "      <td>1288.651667</td>\n",
       "      <td>1295.703247</td>\n",
       "      <td>16608317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2020-05-19 00:00:00+05:30  1325.683498  1329.959932  1276.777905  1281.918579   \n",
       "2020-05-20 00:00:00+05:30  1282.919525  1316.448343  1267.451656  1304.483521   \n",
       "2020-05-21 00:00:00+05:30  1305.666277  1329.732380  1296.567574  1311.353027   \n",
       "2020-05-22 00:00:00+05:30  1320.952305  1326.593448  1297.932505  1302.527344   \n",
       "2020-05-26 00:00:00+05:30  1317.631133  1319.041449  1288.651667  1295.703247   \n",
       "\n",
       "                             Volume  \n",
       "Date                                 \n",
       "2020-05-19 00:00:00+05:30  21157927  \n",
       "2020-05-20 00:00:00+05:30  27660492  \n",
       "2020-05-21 00:00:00+05:30  19583990  \n",
       "2020-05-22 00:00:00+05:30  18914486  \n",
       "2020-05-26 00:00:00+05:30  16608317  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "symbol = \"RELIANCE.NS\"\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=1500)  # Increased historical data\n",
    "\n",
    "df = fetch_stock_data(symbol, start_date, end_date)\n",
    "df = df[[ 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([140, 141, 142, 143, 147, 148, 149, 150, 153, 154,\n",
       "       ...\n",
       "       164, 165, 166, 170, 171, 172, 173, 176, 177, 178],\n",
       "      dtype='int32', name='Date', length=1018)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_technical_indicators(df)\n",
    "df = add_derived_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ADX</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume_Roll_Mean_10</th>\n",
       "      <th>Close_Roll_Mean_20</th>\n",
       "      <th>Close_Roll_Std_20</th>\n",
       "      <th>Volume_Roll_Mean_20</th>\n",
       "      <th>Fourier_Cos_5</th>\n",
       "      <th>Fourier_Sin_5</th>\n",
       "      <th>Fourier_Cos_10</th>\n",
       "      <th>Fourier_Sin_10</th>\n",
       "      <th>Fourier_Cos_21</th>\n",
       "      <th>Fourier_Sin_21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-19 00:00:00+05:30</th>\n",
       "      <td>1325.683498</td>\n",
       "      <td>1329.959932</td>\n",
       "      <td>1276.777905</td>\n",
       "      <td>1281.918579</td>\n",
       "      <td>21157927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.858022e-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.429011e-15</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-20 00:00:00+05:30</th>\n",
       "      <td>1282.919525</td>\n",
       "      <td>1316.448343</td>\n",
       "      <td>1267.451656</td>\n",
       "      <td>1304.483521</td>\n",
       "      <td>27660492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>9.510565e-01</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-9.749279e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21 00:00:00+05:30</th>\n",
       "      <td>1305.666277</td>\n",
       "      <td>1329.732380</td>\n",
       "      <td>1296.567574</td>\n",
       "      <td>1311.353027</td>\n",
       "      <td>19583990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>9.510565e-01</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>-9.972038e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22 00:00:00+05:30</th>\n",
       "      <td>1320.952305</td>\n",
       "      <td>1326.593448</td>\n",
       "      <td>1297.932505</td>\n",
       "      <td>1302.527344</td>\n",
       "      <td>18914486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-5.877853e-01</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>9.510565e-01</td>\n",
       "      <td>0.365341</td>\n",
       "      <td>-9.308737e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-26 00:00:00+05:30</th>\n",
       "      <td>1317.631133</td>\n",
       "      <td>1319.041449</td>\n",
       "      <td>1288.651667</td>\n",
       "      <td>1295.703247</td>\n",
       "      <td>16608317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.714506e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2020-05-19 00:00:00+05:30  1325.683498  1329.959932  1276.777905  1281.918579   \n",
       "2020-05-20 00:00:00+05:30  1282.919525  1316.448343  1267.451656  1304.483521   \n",
       "2020-05-21 00:00:00+05:30  1305.666277  1329.732380  1296.567574  1311.353027   \n",
       "2020-05-22 00:00:00+05:30  1320.952305  1326.593448  1297.932505  1302.527344   \n",
       "2020-05-26 00:00:00+05:30  1317.631133  1319.041449  1288.651667  1295.703247   \n",
       "\n",
       "                             Volume  SMA_20  SMA_50  EMA_20  MACD  ADX  ...  \\\n",
       "Date                                                                    ...   \n",
       "2020-05-19 00:00:00+05:30  21157927     NaN     NaN     NaN   NaN  0.0  ...   \n",
       "2020-05-20 00:00:00+05:30  27660492     NaN     NaN     NaN   NaN  0.0  ...   \n",
       "2020-05-21 00:00:00+05:30  19583990     NaN     NaN     NaN   NaN  0.0  ...   \n",
       "2020-05-22 00:00:00+05:30  18914486     NaN     NaN     NaN   NaN  0.0  ...   \n",
       "2020-05-26 00:00:00+05:30  16608317     NaN     NaN     NaN   NaN  0.0  ...   \n",
       "\n",
       "                           Volume_Roll_Mean_10  Close_Roll_Mean_20  \\\n",
       "Date                                                                 \n",
       "2020-05-19 00:00:00+05:30                  NaN                 NaN   \n",
       "2020-05-20 00:00:00+05:30                  NaN                 NaN   \n",
       "2020-05-21 00:00:00+05:30                  NaN                 NaN   \n",
       "2020-05-22 00:00:00+05:30                  NaN                 NaN   \n",
       "2020-05-26 00:00:00+05:30                  NaN                 NaN   \n",
       "\n",
       "                           Close_Roll_Std_20  Volume_Roll_Mean_20  \\\n",
       "Date                                                                \n",
       "2020-05-19 00:00:00+05:30                NaN                  NaN   \n",
       "2020-05-20 00:00:00+05:30                NaN                  NaN   \n",
       "2020-05-21 00:00:00+05:30                NaN                  NaN   \n",
       "2020-05-22 00:00:00+05:30                NaN                  NaN   \n",
       "2020-05-26 00:00:00+05:30                NaN                  NaN   \n",
       "\n",
       "                           Fourier_Cos_5  Fourier_Sin_5  Fourier_Cos_10  \\\n",
       "Date                                                                      \n",
       "2020-05-19 00:00:00+05:30       1.000000  -6.858022e-15        1.000000   \n",
       "2020-05-20 00:00:00+05:30       0.309017   9.510565e-01        0.809017   \n",
       "2020-05-21 00:00:00+05:30      -0.809017   5.877853e-01        0.309017   \n",
       "2020-05-22 00:00:00+05:30      -0.809017  -5.877853e-01       -0.309017   \n",
       "2020-05-26 00:00:00+05:30      -0.809017   5.877853e-01       -0.309017   \n",
       "\n",
       "                           Fourier_Sin_10  Fourier_Cos_21  Fourier_Sin_21  \n",
       "Date                                                                       \n",
       "2020-05-19 00:00:00+05:30   -3.429011e-15       -0.500000   -8.660254e-01  \n",
       "2020-05-20 00:00:00+05:30    5.877853e-01       -0.222521   -9.749279e-01  \n",
       "2020-05-21 00:00:00+05:30    9.510565e-01        0.074730   -9.972038e-01  \n",
       "2020-05-22 00:00:00+05:30    9.510565e-01        0.365341   -9.308737e-01  \n",
       "2020-05-26 00:00:00+05:30   -9.510565e-01        1.000000   -1.714506e-15  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows 1018, No of Columns 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"No of rows {df.shape[0]}, No of Columns {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data_for_model(df)\n",
    "X = feature_selection(X, y)\n",
    "# X_pca, pca = apply_pca(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ADX</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stoch_Osc</th>\n",
       "      <th>Williams_R</th>\n",
       "      <th>BBlow</th>\n",
       "      <th>BBmid</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_Roll_Std_5</th>\n",
       "      <th>Volume_Roll_Mean_5</th>\n",
       "      <th>Close_Roll_Mean_10</th>\n",
       "      <th>Close_Roll_Std_10</th>\n",
       "      <th>Volume_Roll_Mean_10</th>\n",
       "      <th>Close_Roll_Mean_20</th>\n",
       "      <th>Close_Roll_Std_20</th>\n",
       "      <th>Volume_Roll_Mean_20</th>\n",
       "      <th>Fourier_Cos_21</th>\n",
       "      <th>Fourier_Sin_21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-28 00:00:00+05:30</th>\n",
       "      <td>1751.265771</td>\n",
       "      <td>1563.624546</td>\n",
       "      <td>1771.622142</td>\n",
       "      <td>20.215582</td>\n",
       "      <td>53.422859</td>\n",
       "      <td>81.992962</td>\n",
       "      <td>94.885424</td>\n",
       "      <td>-5.114576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1751.265771</td>\n",
       "      <td>...</td>\n",
       "      <td>67.709534</td>\n",
       "      <td>37412182.6</td>\n",
       "      <td>1830.109192</td>\n",
       "      <td>115.747193</td>\n",
       "      <td>35162319.7</td>\n",
       "      <td>1751.265771</td>\n",
       "      <td>120.839408</td>\n",
       "      <td>27886564.70</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-29 00:00:00+05:30</th>\n",
       "      <td>1767.988403</td>\n",
       "      <td>1576.295098</td>\n",
       "      <td>1785.319669</td>\n",
       "      <td>14.499729</td>\n",
       "      <td>52.526176</td>\n",
       "      <td>69.569951</td>\n",
       "      <td>74.513448</td>\n",
       "      <td>-25.486552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1767.988403</td>\n",
       "      <td>...</td>\n",
       "      <td>44.521072</td>\n",
       "      <td>38701376.8</td>\n",
       "      <td>1853.190662</td>\n",
       "      <td>106.127703</td>\n",
       "      <td>31812001.0</td>\n",
       "      <td>1767.988403</td>\n",
       "      <td>119.166122</td>\n",
       "      <td>28991547.10</td>\n",
       "      <td>0.955573</td>\n",
       "      <td>2.947552e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 00:00:00+05:30</th>\n",
       "      <td>1783.907446</td>\n",
       "      <td>1588.737266</td>\n",
       "      <td>1798.774169</td>\n",
       "      <td>10.021093</td>\n",
       "      <td>51.693541</td>\n",
       "      <td>70.299429</td>\n",
       "      <td>77.557398</td>\n",
       "      <td>-22.442602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1783.907446</td>\n",
       "      <td>...</td>\n",
       "      <td>30.741908</td>\n",
       "      <td>40153746.2</td>\n",
       "      <td>1877.441504</td>\n",
       "      <td>89.614782</td>\n",
       "      <td>32406787.0</td>\n",
       "      <td>1783.907446</td>\n",
       "      <td>117.958218</td>\n",
       "      <td>30093244.90</td>\n",
       "      <td>0.826239</td>\n",
       "      <td>5.633201e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31 00:00:00+05:30</th>\n",
       "      <td>1796.660950</td>\n",
       "      <td>1600.279207</td>\n",
       "      <td>1807.314731</td>\n",
       "      <td>3.384438</td>\n",
       "      <td>50.497824</td>\n",
       "      <td>64.592906</td>\n",
       "      <td>67.140705</td>\n",
       "      <td>-32.859295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1796.660950</td>\n",
       "      <td>...</td>\n",
       "      <td>41.108892</td>\n",
       "      <td>35589815.0</td>\n",
       "      <td>1891.638452</td>\n",
       "      <td>76.906997</td>\n",
       "      <td>33668351.8</td>\n",
       "      <td>1796.660950</td>\n",
       "      <td>114.566987</td>\n",
       "      <td>31231339.75</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>7.818315e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-03 00:00:00+05:30</th>\n",
       "      <td>1803.841644</td>\n",
       "      <td>1610.936086</td>\n",
       "      <td>1809.986789</td>\n",
       "      <td>-5.217867</td>\n",
       "      <td>48.377300</td>\n",
       "      <td>57.587237</td>\n",
       "      <td>52.644687</td>\n",
       "      <td>-47.355313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1803.841644</td>\n",
       "      <td>...</td>\n",
       "      <td>56.240410</td>\n",
       "      <td>32230870.6</td>\n",
       "      <td>1899.778394</td>\n",
       "      <td>63.930087</td>\n",
       "      <td>34174474.0</td>\n",
       "      <td>1803.841644</td>\n",
       "      <td>112.120424</td>\n",
       "      <td>31223819.70</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>9.749279e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                SMA_20       SMA_50       EMA_20       MACD  \\\n",
       "Date                                                                          \n",
       "2020-07-28 00:00:00+05:30  1751.265771  1563.624546  1771.622142  20.215582   \n",
       "2020-07-29 00:00:00+05:30  1767.988403  1576.295098  1785.319669  14.499729   \n",
       "2020-07-30 00:00:00+05:30  1783.907446  1588.737266  1798.774169  10.021093   \n",
       "2020-07-31 00:00:00+05:30  1796.660950  1600.279207  1807.314731   3.384438   \n",
       "2020-08-03 00:00:00+05:30  1803.841644  1610.936086  1809.986789  -5.217867   \n",
       "\n",
       "                                 ADX        RSI  Stoch_Osc  Williams_R  BBlow  \\\n",
       "Date                                                                            \n",
       "2020-07-28 00:00:00+05:30  53.422859  81.992962  94.885424   -5.114576    1.0   \n",
       "2020-07-29 00:00:00+05:30  52.526176  69.569951  74.513448  -25.486552    0.0   \n",
       "2020-07-30 00:00:00+05:30  51.693541  70.299429  77.557398  -22.442602    0.0   \n",
       "2020-07-31 00:00:00+05:30  50.497824  64.592906  67.140705  -32.859295    0.0   \n",
       "2020-08-03 00:00:00+05:30  48.377300  57.587237  52.644687  -47.355313    0.0   \n",
       "\n",
       "                                 BBmid  ...  Close_Roll_Std_5  \\\n",
       "Date                                    ...                     \n",
       "2020-07-28 00:00:00+05:30  1751.265771  ...         67.709534   \n",
       "2020-07-29 00:00:00+05:30  1767.988403  ...         44.521072   \n",
       "2020-07-30 00:00:00+05:30  1783.907446  ...         30.741908   \n",
       "2020-07-31 00:00:00+05:30  1796.660950  ...         41.108892   \n",
       "2020-08-03 00:00:00+05:30  1803.841644  ...         56.240410   \n",
       "\n",
       "                           Volume_Roll_Mean_5  Close_Roll_Mean_10  \\\n",
       "Date                                                                \n",
       "2020-07-28 00:00:00+05:30          37412182.6         1830.109192   \n",
       "2020-07-29 00:00:00+05:30          38701376.8         1853.190662   \n",
       "2020-07-30 00:00:00+05:30          40153746.2         1877.441504   \n",
       "2020-07-31 00:00:00+05:30          35589815.0         1891.638452   \n",
       "2020-08-03 00:00:00+05:30          32230870.6         1899.778394   \n",
       "\n",
       "                           Close_Roll_Std_10  Volume_Roll_Mean_10  \\\n",
       "Date                                                                \n",
       "2020-07-28 00:00:00+05:30         115.747193           35162319.7   \n",
       "2020-07-29 00:00:00+05:30         106.127703           31812001.0   \n",
       "2020-07-30 00:00:00+05:30          89.614782           32406787.0   \n",
       "2020-07-31 00:00:00+05:30          76.906997           33668351.8   \n",
       "2020-08-03 00:00:00+05:30          63.930087           34174474.0   \n",
       "\n",
       "                           Close_Roll_Mean_20  Close_Roll_Std_20  \\\n",
       "Date                                                               \n",
       "2020-07-28 00:00:00+05:30         1751.265771         120.839408   \n",
       "2020-07-29 00:00:00+05:30         1767.988403         119.166122   \n",
       "2020-07-30 00:00:00+05:30         1783.907446         117.958218   \n",
       "2020-07-31 00:00:00+05:30         1796.660950         114.566987   \n",
       "2020-08-03 00:00:00+05:30         1803.841644         112.120424   \n",
       "\n",
       "                           Volume_Roll_Mean_20  Fourier_Cos_21  Fourier_Sin_21  \n",
       "Date                                                                            \n",
       "2020-07-28 00:00:00+05:30          27886564.70        1.000000   -2.449294e-15  \n",
       "2020-07-29 00:00:00+05:30          28991547.10        0.955573    2.947552e-01  \n",
       "2020-07-30 00:00:00+05:30          30093244.90        0.826239    5.633201e-01  \n",
       "2020-07-31 00:00:00+05:30          31231339.75        0.623490    7.818315e-01  \n",
       "2020-08-03 00:00:00+05:30          31223819.70       -0.222521    9.749279e-01  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test, scaler = split_and_scale_data(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-27 06:23:07,440] A new study created in memory with name: no-name-214d81b4-0896-41d2-8d31-2369fe07d1c5\n",
      "/tmp/ipykernel_4617/3614958397.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-3, 1.0),\n",
      "/tmp/ipykernel_4617/3614958397.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('xgb_subsample', 0.6, 1.0),\n",
      "/tmp/ipykernel_4617/3614958397.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('xgb_colsample_bytree', 0.6, 1.0),\n",
      "/tmp/ipykernel_4617/3614958397.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('lgb_learning_rate', 1e-3, 1.0),\n",
      "/tmp/ipykernel_4617/3614958397.py:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('lgb_subsample', 0.6, 1.0),\n",
      "/tmp/ipykernel_4617/3614958397.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('lgb_colsample_bytree', 0.6, 1.0),\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[W 2024-06-27 06:23:07,512] Trial 0 failed with parameters: {'xgb_max_depth': 6, 'xgb_learning_rate': 0.0916000310155272, 'xgb_n_estimators': 133, 'xgb_min_child_weight': 5, 'xgb_subsample': 0.7719998314269622, 'xgb_colsample_bytree': 0.9652527226244636, 'lgb_num_leaves': 63, 'lgb_learning_rate': 0.22587236227784482, 'lgb_n_estimators': 231, 'lgb_min_child_samples': 57, 'lgb_subsample': 0.801679779949622, 'lgb_colsample_bytree': 0.8790397623308244, 'gru_units': 117, 'gru_layers': 1} because of the following error: ValueError('The estimator Sequential should be a regressor.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_4617/3614958397.py\", line 40, in objective\n",
      "    stacked_model.fit(X_train_scaled, y_train)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py\", line 956, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py\", line 191, in fit\n",
      "    names, all_estimators = self._validate_estimators()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_base.py\", line 282, in _validate_estimators\n",
      "    raise ValueError(\n",
      "ValueError: The estimator Sequential should be a regressor.\n",
      "[W 2024-06-27 06:23:07,519] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator Sequential should be a regressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[276], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[237], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(X_train, y_train, X_test, y_test):\n\u001b[1;32m      2\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Increased number of trials\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# [Create models with best parameters]\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[236], line 40\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     29\u001b[0m stacked_model \u001b[38;5;241m=\u001b[39m StackingRegressor(\n\u001b[1;32m     30\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     31\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb_model),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mxgb\u001b[38;5;241m.\u001b[39mXGBRegressor(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mstacked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m stacked_model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m     42\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:956\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;03m    Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    955\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:191\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mself : object\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# all_estimators contains all estimators, the one to be fitted and the\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# 'drop' string.\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m names, all_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_final_estimator()\n\u001b[1;32m    194\u001b[0m stack_method \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_estimators)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_base.py:282\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    284\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m    285\u001b[0m             )\n\u001b[1;32m    286\u001b[0m         )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[0;31mValueError\u001b[0m: The estimator Sequential should be a regressor."
     ]
    }
   ],
   "source": [
    "model = train_model(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
